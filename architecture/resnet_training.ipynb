{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.6.0+cpu\n",
      "Torchvision Version:  0.21.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "MAIN_FOLDER = Path(CURRENT_DIR).parent\n",
    "OUTPUT_FOLDER = os.path.join(CURRENT_DIR, 'aligned')  \n",
    "FOLD_DATA = os.path.join(CURRENT_DIR, 'fold_data') \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "def get_data_transforms():\n",
    "    normalize = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "\n",
    "    return {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*normalize)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*normalize)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(*normalize)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "data_transforms = get_data_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[idx], dtype=torch.long)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folds_dataset(image_root, fold_dir, fold_files):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for fold_file in fold_files:\n",
    "        print(f\"Reading fold file: {fold_file}\")\n",
    "        with open(os.path.join(fold_dir, fold_file), 'r') as f:\n",
    "            next(f)  \n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                user_id = parts[0]\n",
    "                original_img_name = parts[1]\n",
    "                gender = parts[4].lower()\n",
    "\n",
    "                if gender not in [\"m\", \"f\"]:\n",
    "                    continue\n",
    "                label = 0 if gender == \"m\" else 1\n",
    "\n",
    "                user_folder = os.path.join(image_root, user_id)\n",
    "                if not os.path.isdir(user_folder):\n",
    "                    continue\n",
    "\n",
    "                for file in os.listdir(user_folder):\n",
    "                    if original_img_name in file:\n",
    "                        full_path = os.path.join(user_folder, file)\n",
    "                        if os.path.isfile(full_path):\n",
    "                            image_paths.append(full_path)\n",
    "                            labels.append(label)\n",
    "                        break\n",
    "\n",
    "    return image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size, train_folds, val_fold):\n",
    "    train_image_paths, train_labels = load_folds_dataset(OUTPUT_FOLDER, FOLD_DATA, train_folds)\n",
    "    val_image_paths, val_labels = load_folds_dataset(OUTPUT_FOLDER, FOLD_DATA, [val_fold])\n",
    "\n",
    "    train_dataset = BasicImageDataset(train_image_paths, train_labels, transform=data_transforms['train'])\n",
    "    val_dataset = BasicImageDataset(val_image_paths, val_labels, transform=data_transforms['val'])\n",
    "\n",
    "    print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
    "\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        return None\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    return {'train': train_loader, 'val': val_loader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResnetGender(nn.Module):\n",
    "#     def __init__(self, layers=18, pretrained=True, drop_rate=0.3):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         if layers == 18:\n",
    "#             base_model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "#             block_expansion = 1\n",
    "\n",
    "#         self.resnet = nn.Sequential(*list(base_model.children())[:-1]) \n",
    "#         self.pool = nn.AdaptiveAvgPool2d((1, 1))  \n",
    "        \n",
    "#         self.extra_layer = nn.Sequential(\n",
    "#             nn.Linear(block_expansion * 512, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.Dropout(drop_rate),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "#         self.gender_predictor = nn.Sequential(\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Dropout(drop_rate),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 2)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.extra_layer(x)\n",
    "#         return self.gender_predictor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, eps=0.1, reduction='mean'):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        if self.reduction=='sum':\n",
    "            loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=-1)\n",
    "            if self.reduction=='mean':\n",
    "                loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize model resnet18\n",
    "def load_model(drop_rate=0.3):\n",
    "    base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    num_ftrs = base_model.fc.in_features\n",
    "    base_model.fc = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.Dropout(drop_rate),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)  \n",
    "    )\n",
    "    return base_model.to(DEVICE)\n",
    "\n",
    "# def load_model(drop_rate=0.3):\n",
    "#     return ResnetGender(layers=18, pretrained=True, drop_rate=drop_rate).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=50, patience=10):\n",
    "    criterion = LabelSmoothingCrossEntropy()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.25)\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_prec': [], 'val_prec': [],\n",
    "        'train_rec': [], 'val_rec': [],\n",
    "        'train_f1': [], 'val_f1': [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            all_preds, all_labels = [], []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc)\n",
    "            history[f'{phase}_prec'].append(epoch_prec)\n",
    "            history[f'{phase}_rec'].append(epoch_rec)\n",
    "            history[f'{phase}_f1'].append(epoch_f1)\n",
    "\n",
    "            print(f\"{phase.upper()} — Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "                  f\"Prec: {epoch_prec:.4f} | Rec: {epoch_rec:.4f} | F1: {epoch_f1:.4f}\")\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "            \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    def plot_training_curves(history):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Validation Accuracy over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Validation Loss over Epochs\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_training_curves(history)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"\\nTraining complete — Best Val Loss: {best_loss:.4f}\")\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Val = fold_0_data.txt, Train = ['fold_1_data.txt', 'fold_2_data.txt', 'fold_3_data.txt', 'fold_4_data.txt']\n",
      "Reading fold file: fold_1_data.txt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\All Saints\\\\Desktop\\\\Uni mods\\\\SC4001\\\\CZ4042-SC4001-NND\\\\architecture\\\\fold_data\\\\fold_1_data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m train_folds = [f \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_folds) \u001b[38;5;28;01mif\u001b[39;00m i != fold_idx]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Val = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_fold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Train = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m dataloaders = \u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m model = load_model(drop_rate=\u001b[32m0.3\u001b[39m)\n\u001b[32m     10\u001b[39m params_to_update = [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model.parameters() \u001b[38;5;28;01mif\u001b[39;00m p.requires_grad]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mget_dataloaders\u001b[39m\u001b[34m(batch_size, train_folds, val_fold)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_dataloaders\u001b[39m(batch_size, train_folds, val_fold):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_image_paths, train_labels = \u001b[43mload_folds_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFOLD_DATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_folds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     val_image_paths, val_labels = load_folds_dataset(OUTPUT_FOLDER, FOLD_DATA, [val_fold])\n\u001b[32m      5\u001b[39m     train_dataset = BasicImageDataset(train_image_paths, train_labels, transform=data_transforms[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mload_folds_dataset\u001b[39m\u001b[34m(image_root, fold_dir, fold_files)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_file \u001b[38;5;129;01min\u001b[39;00m fold_files:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReading fold file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mnext\u001b[39m(f)  \n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\All Saints\\\\Desktop\\\\Uni mods\\\\SC4001\\\\CZ4042-SC4001-NND\\\\architecture\\\\fold_data\\\\fold_1_data.txt'"
     ]
    }
   ],
   "source": [
    "all_folds = [f\"fold_{i}_data.txt\" for i in range(5)]\n",
    "for fold_idx in range(5):\n",
    "    val_fold = all_folds[fold_idx]\n",
    "    train_folds = [f for i, f in enumerate(all_folds) if i != fold_idx]\n",
    "    print(f\"Fold {fold_idx}: Val = {val_fold}, Train = {train_folds}\")\n",
    "\n",
    "    dataloaders = get_dataloaders(batch_size=32, train_folds=train_folds, val_fold=val_fold)\n",
    "\n",
    "    model = load_model(drop_rate=0.3)\n",
    "    params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params_to_update, lr=0.001)\n",
    "\n",
    "    model, history = train_model(model, dataloaders, optimizer, num_epochs=50)\n",
    "    best_val_acc = max(history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as efficientnet_test.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model, 'resnet_test.pth')\n",
    "print(\"Model saved as efficientnet_test.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
