{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.6.0+cpu\n",
      "Torchvision Version:  0.21.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import optuna\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "MAIN_FOLDER = Path(CURRENT_DIR).parent\n",
    "OUTPUT_FOLDER = os.path.join(MAIN_FOLDER, 'aligned')  \n",
    "FOLD_DATA = os.path.join(MAIN_FOLDER, 'fold_data') \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "def get_data_transforms():\n",
    "    normalize = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "    return {\n",
    "        'train': transforms.Compose([transforms.ToTensor(), transforms.Normalize(*normalize)]),\n",
    "        'val': transforms.Compose([transforms.ToTensor(), transforms.Normalize(*normalize)]),\n",
    "    }\n",
    "\n",
    "data_transforms = get_data_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folds_dataset(image_root, fold_dir, fold_files):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for fold_file in fold_files:\n",
    "        print(f\"Reading fold file: {fold_file}\")\n",
    "        with open(os.path.join(fold_dir, fold_file), 'r') as f:\n",
    "            next(f)  \n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                user_id = parts[0]\n",
    "                original_img_name = parts[1]\n",
    "                gender = parts[4].lower()\n",
    "\n",
    "                if gender not in [\"m\", \"f\"]:\n",
    "                    continue\n",
    "                label = 0 if gender == \"m\" else 1\n",
    "\n",
    "                user_folder = os.path.join(image_root, user_id)\n",
    "                if not os.path.isdir(user_folder):\n",
    "                    continue\n",
    "\n",
    "                for file in os.listdir(user_folder):\n",
    "                    if original_img_name in file:\n",
    "                        full_path = os.path.join(user_folder, file)\n",
    "                        if os.path.isfile(full_path):\n",
    "                            image_paths.append(full_path)\n",
    "                            labels.append(label)\n",
    "                        break\n",
    "\n",
    "    return image_paths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[idx], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size, train_folds, val_fold):\n",
    "    train_image_paths, train_labels = load_folds_dataset(OUTPUT_FOLDER, FOLD_DATA, train_folds)\n",
    "    val_image_paths, val_labels = load_folds_dataset(OUTPUT_FOLDER, FOLD_DATA, [val_fold])\n",
    "\n",
    "    train_dataset = BasicImageDataset(train_image_paths, train_labels, transform=data_transforms['train'])\n",
    "    val_dataset = BasicImageDataset(val_image_paths, val_labels, transform=data_transforms['val'])\n",
    "\n",
    "    print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
    "\n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        return None\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return {'train': train_loader, 'val': val_loader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize model\n",
    "def load_model(num_classes):\n",
    "    model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    model.num_classes = num_classes\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, optimizer, num_epochs=25, patience=5, trial=None):\n",
    "    criterion = nn.BCELoss()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_prec': [], 'val_prec': [],\n",
    "        'train_rec': [], 'val_rec': [],\n",
    "        'train_f1': [], 'val_f1': [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            all_preds, all_labels = [], []\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = torch.sigmoid(outputs.squeeze())\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = (outputs > 0.5).long()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc)\n",
    "            history[f'{phase}_prec'].append(epoch_prec)\n",
    "            history[f'{phase}_rec'].append(epoch_rec)\n",
    "            history[f'{phase}_f1'].append(epoch_f1)\n",
    "\n",
    "            print(f\"{phase.upper()} — Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "                  f\"Prec: {epoch_prec:.4f} | Rec: {epoch_rec:.4f} | F1: {epoch_f1:.4f}\")\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_f1 > best_f1:\n",
    "                    best_f1 = epoch_f1\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"\\nTraining complete — Best Val F1: {best_f1:.4f}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    all_folds = [f\"fold_{i}_data.txt\" for i in range(5)]\n",
    "\n",
    "    for fold_idx in range(5):\n",
    "        val_fold = all_folds[fold_idx]\n",
    "        train_folds = [f for i, f in enumerate(all_folds) if i != fold_idx]\n",
    "\n",
    "        print(f\"Fold {fold_idx}: Val = {val_fold}, Train = {train_folds}\")\n",
    "        dataloaders = get_dataloaders(batch_size, train_folds, val_fold)\n",
    "\n",
    "        if dataloaders is None:\n",
    "            print(f\"Skipping fold {fold_idx} due to empty dataset.\")\n",
    "            continue\n",
    "\n",
    "        model = load_model(NUM_CLASSES)\n",
    "\n",
    "        params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = optim.Adam(params_to_update, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        model, history = train_model(model, dataloaders, optimizer, num_epochs=50, trial=trial)\n",
    "\n",
    "        best_val_acc = max(best_val_acc, max(history['val_acc']))\n",
    "\n",
    "    return best_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-31 17:28:13,121] A new study created in memory with name: no-name-75dbf638-9321-48a5-8c74-1556903545ee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Val = fold_0_data.txt, Train = ['fold_1_data.txt', 'fold_2_data.txt', 'fold_3_data.txt', 'fold_4_data.txt']\n",
      "Reading fold file: fold_1_data.txt\n",
      "Reading fold file: fold_2_data.txt\n",
      "Reading fold file: fold_3_data.txt\n",
      "Reading fold file: fold_4_data.txt\n",
      "Reading fold file: fold_0_data.txt\n",
      "Train size: 13497, Val size: 3995\n",
      "\n",
      "Epoch 1/50\n",
      "TRAIN — Loss: 0.6568 | Acc: 0.6057 | Prec: 0.5910 | Rec: 0.9197 | F1: 0.7196\n",
      "VAL — Loss: 0.6410 | Acc: 0.6458 | Prec: 0.5971 | Rec: 0.8414 | F1: 0.6985\n",
      "\n",
      "Epoch 2/50\n",
      "TRAIN — Loss: 0.6073 | Acc: 0.6881 | Prec: 0.6821 | Rec: 0.8109 | F1: 0.7409\n",
      "VAL — Loss: 0.6027 | Acc: 0.6809 | Prec: 0.6455 | Rec: 0.7664 | F1: 0.7008\n",
      "\n",
      "Epoch 3/50\n",
      "TRAIN — Loss: 0.5712 | Acc: 0.7175 | Prec: 0.7321 | Rec: 0.7671 | F1: 0.7492\n",
      "VAL — Loss: 0.5801 | Acc: 0.7021 | Prec: 0.6815 | Rec: 0.7305 | F1: 0.7052\n",
      "\n",
      "Epoch 4/50\n",
      "TRAIN — Loss: 0.5434 | Acc: 0.7376 | Prec: 0.7588 | Rec: 0.7667 | F1: 0.7627\n",
      "VAL — Loss: 0.5703 | Acc: 0.7099 | Prec: 0.6887 | Rec: 0.7392 | F1: 0.7130\n",
      "\n",
      "Epoch 5/50\n",
      "TRAIN — Loss: 0.5217 | Acc: 0.7548 | Prec: 0.7727 | Rec: 0.7850 | F1: 0.7788\n",
      "VAL — Loss: 0.5591 | Acc: 0.7159 | Prec: 0.7121 | Rec: 0.7007 | F1: 0.7063\n",
      "\n",
      "Epoch 6/50\n",
      "TRAIN — Loss: 0.5047 | Acc: 0.7645 | Prec: 0.7804 | Rec: 0.7958 | F1: 0.7880\n",
      "VAL — Loss: 0.5566 | Acc: 0.7166 | Prec: 0.6981 | Rec: 0.7382 | F1: 0.7176\n",
      "\n",
      "Epoch 7/50\n",
      "TRAIN — Loss: 0.4882 | Acc: 0.7756 | Prec: 0.7896 | Rec: 0.8071 | F1: 0.7982\n",
      "VAL — Loss: 0.5582 | Acc: 0.7186 | Prec: 0.7064 | Rec: 0.7238 | F1: 0.7150\n",
      "\n",
      "Epoch 8/50\n",
      "TRAIN — Loss: 0.4693 | Acc: 0.7840 | Prec: 0.7975 | Rec: 0.8141 | F1: 0.8057\n",
      "VAL — Loss: 0.5591 | Acc: 0.7161 | Prec: 0.6985 | Rec: 0.7351 | F1: 0.7164\n",
      "\n",
      "Epoch 9/50\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Optimization Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")  \n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Val Accuracy: {trial.value:.4f}\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# torch.save(model, 'efficientnet_test.pth')\n",
    "# print(\"Model saved as efficientnet_test.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
